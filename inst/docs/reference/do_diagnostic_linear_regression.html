<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Do the diagnostic test for lm model assumption — do_diagnostic_linear_regression • packDAMipd</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Do the diagnostic test for lm model assumption — do_diagnostic_linear_regression" />
<meta property="og:description" content="Do the diagnostic test for lm model assumption" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">packDAMipd</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/cycle_dependent.html">Cycle dependent</a>
    </li>
    <li>
      <a href="../articles/Deterministic_sensitivity_analysis.html">Deterministic sensitivity analysis</a>
    </li>
    <li>
      <a href="../articles/Probabilstic_sensitivity_analysis.html">Probabilistic sensitivity analysis</a>
    </li>
    <li>
      <a href="../articles/Sick_sicker_age_dependent.html">Sick sicker age dependent</a>
    </li>
    <li>
      <a href="../articles/Simple_sick_sicker.html">Simple sick sicker model</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/sheejamk/packDAMipd/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Do the diagnostic test for lm model assumption</h1>
    <small class="dont-index">Source: <a href='https://github.com/sheejamk/packDAMipd/blob/master/R/help_parameter_estimation_functions.R'><code>R/help_parameter_estimation_functions.R</code></a></small>
    <div class="hidden name"><code>do_diagnostic_linear_regression.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Do the diagnostic test for lm model assumption</p>
    </div>

    <pre class="usage"><span class='fu'>do_diagnostic_linear_regression</span><span class='op'>(</span>
  <span class='va'>method</span>,
  <span class='va'>fit</span>,
  <span class='va'>expression_recreated</span>,
  <span class='va'>param_to_be_estimated</span>,
  <span class='va'>dataset</span>,
  <span class='va'>indep_var</span>,
  <span class='va'>covariates</span>,
  <span class='va'>interaction</span>
<span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>method</th>
      <td><p>param describing the methods, expects lm</p></td>
    </tr>
    <tr>
      <th>expression_recreated</th>
      <td><p>the expression recreated for calling lm</p></td>
    </tr>
    <tr>
      <th>param_to_be_estimated</th>
      <td><p>parameter of interest</p></td>
    </tr>
    <tr>
      <th>dataset</th>
      <td><p>data set to be provided</p></td>
    </tr>
    <tr>
      <th>indep_var</th>
      <td><p>the independent variable (column name in data file)</p></td>
    </tr>
    <tr>
      <th>covariates</th>
      <td><p>list of covariates - calculations to be done before
passing</p></td>
    </tr>
    <tr>
      <th>interaction</th>
      <td><p>boolean value to indicate interaction in the case of
linear regression, false by default</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>the results of the regression analysis</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># \donttest{</span>
<span class='va'>datafile</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/system.file.html'>system.file</a></span><span class='op'>(</span><span class='st'>"extdata"</span>, <span class='st'>"binary.csv"</span>, package <span class='op'>=</span> <span class='st'>"packDAMipd"</span><span class='op'>)</span>
<span class='va'>mydata</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/utils/read.table.html'>read.csv</a></span><span class='op'>(</span><span class='va'>datafile</span><span class='op'>)</span>
<span class='va'>results_logit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='use_linear_regression.html'>use_linear_regression</a></span><span class='op'>(</span><span class='st'>"admit"</span>,dataset <span class='op'>=</span> <span class='va'>mydata</span>,
indep_var <span class='op'>=</span> <span class='st'>"gre"</span>,covariates <span class='op'>=</span> <span class='cn'>NA</span>, interaction <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>
</div><div class='output co'>#&gt; 
#&gt; Call:
#&gt; lm(formula = admit ~ gre, data = dataset)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -0.4755 -0.3415 -0.2522  0.5989  0.8966 
#&gt; 
#&gt; Coefficients:
#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -0.1198407  0.1190510  -1.007 0.314722    
#&gt; gre          0.0007442  0.0001988   3.744 0.000208 ***
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 0.4587 on 398 degrees of freedom
#&gt; Multiple R-squared:  0.03402,	Adjusted R-squared:  0.03159 
#&gt; F-statistic: 14.02 on 1 and 398 DF,  p-value: 0.0002081
#&gt; 
#&gt; 
#&gt; ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS
#&gt; USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:
#&gt; Level of Significance =  0.05 
#&gt; 
#&gt; Call:
#&gt;  gvlma::gvlma(x = fit) 
#&gt; 
#&gt;                        Value   p-value                   Decision
#&gt; Global Stat        65.312437 2.212e-13 Assumptions NOT satisfied!
#&gt; Skewness           36.445627 1.570e-09 Assumptions NOT satisfied!
#&gt; Kurtosis           28.227938 1.078e-07 Assumptions NOT satisfied!
#&gt; Link Function       0.002174 9.628e-01    Assumptions acceptable.
#&gt; Heteroscedasticity  0.636699 4.249e-01    Assumptions acceptable.</div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='input'><span class='fu'>do_diagnostic_linear_regression</span><span class='op'>(</span><span class='st'>"lm"</span>, <span class='va'>results_logit</span><span class='op'>$</span><span class='va'>fit</span>,
<span class='va'>results_logit</span><span class='op'>$</span><span class='va'>fit</span><span class='op'>$</span><span class='va'>call</span>,
<span class='st'>"admit"</span>, <span class='va'>mydata</span>, <span class='st'>"gre"</span>, covariates <span class='op'>=</span> <span class='cn'>NA</span> , interaction<span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>
</div><div class='output co'>#&gt; 
#&gt; Call:
#&gt; lm(formula = admit ~ gre, data = dataset)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -0.4755 -0.3415 -0.2522  0.5989  0.8966 
#&gt; 
#&gt; Coefficients:
#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -0.1198407  0.1190510  -1.007 0.314722    
#&gt; gre          0.0007442  0.0001988   3.744 0.000208 ***
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 0.4587 on 398 degrees of freedom
#&gt; Multiple R-squared:  0.03402,	Adjusted R-squared:  0.03159 
#&gt; F-statistic: 14.02 on 1 and 398 DF,  p-value: 0.0002081
#&gt; 
#&gt; 
#&gt; ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS
#&gt; USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:
#&gt; Level of Significance =  0.05 
#&gt; 
#&gt; Call:
#&gt;  gvlma::gvlma(x = fit) 
#&gt; 
#&gt;                        Value   p-value                   Decision
#&gt; Global Stat        65.312437 2.212e-13 Assumptions NOT satisfied!
#&gt; Skewness           36.445627 1.570e-09 Assumptions NOT satisfied!
#&gt; Kurtosis           28.227938 1.078e-07 Assumptions NOT satisfied!
#&gt; Link Function       0.002174 9.628e-01    Assumptions acceptable.
#&gt; Heteroscedasticity  0.636699 4.249e-01    Assumptions acceptable.</div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='output co'>#&gt; <span class='message'>`geom_smooth()` using formula 'y ~ x'</span></div><div class='output co'>#&gt; $autocorr_error_test
#&gt; 
#&gt; 	Durbin-Watson test
#&gt; 
#&gt; data:  fit
#&gt; DW = 1.9897, p-value = 0.4582
#&gt; alternative hypothesis: true autocorrelation is greater than 0
#&gt; 
#&gt; 
#&gt; $outlier_test
#&gt; No Studentized residuals with Bonferroni p &lt; 0.05
#&gt; Largest |rstudent|:
#&gt;     rstudent unadjusted p-value Bonferroni p
#&gt; 316 1.979889           0.048406           NA
#&gt; 
#&gt; $anova_table
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: admit
#&gt;            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
#&gt; gre         1  2.948 2.94842  14.015 0.0002081 ***
#&gt; Residuals 398 83.729 0.21037                      
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; $non_constant_error_test
#&gt; Non-constant Variance Score Test 
#&gt; Variance formula: ~ fitted.values 
#&gt; Chisquare = 4.860373, Df = 1, p = 0.02748
#&gt; 
#&gt; $influence_fit
#&gt; $influence_fit$hat
#&gt;           1           2           3           4           5           6 
#&gt; 0.010602365 0.003481783 0.010965230 0.003013739 0.003360827 0.008075828 
#&gt;           7           8           9          10          11          12 
#&gt; 0.002644111 0.009117094 0.002927342 0.004868636 0.010965230 0.006597319 
#&gt;          13          14          15          16          17          18 
#&gt; 0.008075828 0.004868636 0.004868636 0.004678563 0.009445401 0.012237890 
#&gt;          19          20          21          22          23          24 
#&gt; 0.010965230 0.002927342 0.003944568 0.003481783 0.002528415 0.004100082 
#&gt;          25          26          27          28          29          30 
#&gt; 0.008075828 0.010965230 0.002695949 0.003360827 0.009445401 0.003360827 
#&gt;          31          32          33          34          35          36 
#&gt; 0.002927342 0.008075828 0.002528415 0.010965230 0.012237890 0.009117094 
#&gt;          37          38          39          40          41          42 
#&gt; 0.002511136 0.003360827 0.003944568 0.003360827 0.002644111 0.002511136 
#&gt;          43          44          45          46          47          48 
#&gt; 0.002528415 0.003944568 0.004868636 0.005562814 0.002511136 0.003944568 
#&gt;          49          50          51          52          53          54 
#&gt; 0.006597319 0.009117094 0.003013739 0.006597319 0.006856509 0.004100082 
#&gt;          55          56          57          58          59          60 
#&gt; 0.003481783 0.006856509 0.002644111 0.010602365 0.009117094 0.002528415 
#&gt;          61          62          63          64          65          66 
#&gt; 0.002695949 0.002644111 0.003013739 0.004100082 0.002511136 0.002528415 
#&gt;          67          68          69          70          71          72 
#&gt; 0.006856509 0.002695949 0.002511136 0.010965230 0.003013739 0.018045995 
#&gt;          73          74          75          76          77          78 
#&gt; 0.004678563 0.002511136 0.005787445 0.005787445 0.002644111 0.010965230 
#&gt;          79          80          81          82          83          84 
#&gt; 0.002927342 0.002695949 0.004868636 0.002695949 0.003944568 0.010602365 
#&gt;          85          86          87          88          89          90 
#&gt; 0.003944568 0.003360827 0.002528415 0.002528415 0.004868636 0.003481783 
#&gt;          91          92          93          94          95          96 
#&gt; 0.004868636 0.005787445 0.010965230 0.002511136 0.003481783 0.003481783 
#&gt;          97          98          99         100         101         102 
#&gt; 0.003013739 0.004678563 0.004868636 0.009117094 0.014023670 0.002511136 
#&gt;         103         104         105         106         107         108 
#&gt; 0.010602365 0.002927342 0.003481783 0.006856509 0.004868636 0.004678563 
#&gt;         109         110         111         112         113         114 
#&gt; 0.009117094 0.004678563 0.004100082 0.007782079 0.012237890 0.002528415 
#&gt;         115         116         117         118         119         120 
#&gt; 0.005787445 0.002695949 0.006597319 0.004868636 0.010965230 0.014023670 
#&gt;         121         122         123         124         125         126 
#&gt; 0.003360827 0.004678563 0.003360827 0.003944568 0.005787445 0.002927342 
#&gt;         127         128         129         130         131         132 
#&gt; 0.002528415 0.006856509 0.002927342 0.005562814 0.002695949 0.003013739 
#&gt;         133         134         135         136         137         138 
#&gt; 0.002511136 0.003944568 0.002644111 0.003944568 0.002644111 0.004868636 
#&gt;         139         140         141         142         143         144 
#&gt; 0.002695949 0.002528415 0.003013739 0.004868636 0.002695949 0.002511136 
#&gt;         145         146         147         148         149         150 
#&gt; 0.002511136 0.010602365 0.004678563 0.002644111 0.004678563 0.006856509 
#&gt;         151         152         153         154         155         156 
#&gt; 0.010965230 0.009117094 0.003013739 0.002511136 0.002695949 0.002511136 
#&gt;         157         158         159         160         161         162 
#&gt; 0.002644111 0.004678563 0.003481783 0.004868636 0.002528415 0.003013739 
#&gt;         163         164         165         166         167         168 
#&gt; 0.004868636 0.003360827 0.002511136 0.004868636 0.006597319 0.005787445 
#&gt;         169         170         171         172         173         174 
#&gt; 0.003944568 0.002528415 0.009117094 0.002927342 0.004100082 0.010965230 
#&gt;         175         176         177         178         179         180 
#&gt; 0.003944568 0.002695949 0.003360827 0.002695949 0.002695949 0.018045995 
#&gt;         181         182         183         184         185         186 
#&gt; 0.002695949 0.003944568 0.004868636 0.002927342 0.003944568 0.010965230 
#&gt;         187         188         189         190         191         192 
#&gt; 0.002644111 0.002511136 0.002644111 0.003944568 0.003013739 0.010965230 
#&gt;         193         194         195         196         197         198 
#&gt; 0.003013739 0.010602365 0.002528415 0.002644111 0.003481783 0.009117094 
#&gt;         199         200         201         202         203         204 
#&gt; 0.002528415 0.002511136 0.010965230 0.002511136 0.004868636 0.007782079 
#&gt;         205         206         207         208         209         210 
#&gt; 0.002528415 0.009445401 0.006856509 0.003013739 0.002927342 0.002511136 
#&gt;         211         212         213         214         215         216 
#&gt; 0.006856509 0.002511136 0.005562814 0.003013739 0.002528415 0.003481783 
#&gt;         217         218         219         220         221         222 
#&gt; 0.014023670 0.005562814 0.005562814 0.002644111 0.002927342 0.004100082 
#&gt;         223         224         225         226         227         228 
#&gt; 0.004678563 0.010965230 0.010965230 0.005787445 0.002695949 0.002927342 
#&gt;         229         230         231         232         233         234 
#&gt; 0.004678563 0.005787445 0.002511136 0.002528415 0.010602365 0.007782079 
#&gt;         235         236         237         238         239         240 
#&gt; 0.010965230 0.002695949 0.003481783 0.004678563 0.003944568 0.004868636 
#&gt;         241         242         243         244         245         246 
#&gt; 0.006597319 0.003360827 0.004100082 0.002695949 0.002927342 0.010965230 
#&gt;         247         248         249         250         251         252 
#&gt; 0.004100082 0.006597319 0.004100082 0.003013739 0.003481783 0.002695949 
#&gt;         253         254         255         256         257         258 
#&gt; 0.003360827 0.002927342 0.006856509 0.003013739 0.003360827 0.002695949 
#&gt;         259         260         261         262         263         264 
#&gt; 0.003360827 0.003013739 0.004100082 0.006597319 0.003360827 0.002695949 
#&gt;         265         266         267         268         269         270 
#&gt; 0.003360827 0.010602365 0.002644111 0.002528415 0.004100082 0.003944568 
#&gt;         271         272         273         274         275         276 
#&gt; 0.003013739 0.002927342 0.004100082 0.003481783 0.003360827 0.002528415 
#&gt;         277         278         279         280         281         282 
#&gt; 0.005562814 0.002511136 0.004100082 0.003481783 0.003481783 0.012237890 
#&gt;         283         284         285         286         287         288 
#&gt; 0.003481783 0.003360827 0.006597319 0.002528415 0.010965230 0.003481783 
#&gt;         289         290         291         292         293         294 
#&gt; 0.010965230 0.007782079 0.002695949 0.010965230 0.004100082 0.010965230 
#&gt;         295         296         297         298         299         300 
#&gt; 0.004678563 0.003360827 0.002644111 0.005562814 0.002927342 0.005787445 
#&gt;         301         302         303         304         305         306 
#&gt; 0.003013739 0.003481783 0.009117094 0.004100082 0.027893704 0.002511136 
#&gt;         307         308         309         310         311         312 
#&gt; 0.002927342 0.002511136 0.002927342 0.006597319 0.002644111 0.003481783 
#&gt;         313         314         315         316         317         318 
#&gt; 0.003481783 0.003360827 0.002927342 0.018045995 0.014023670 0.009445401 
#&gt;         319         320         321         322         323         324 
#&gt; 0.004678563 0.002927342 0.005562814 0.005562814 0.003944568 0.007782079 
#&gt;         325         326         327         328         329         330 
#&gt; 0.003360827 0.004100082 0.004100082 0.002644111 0.002511136 0.003944568 
#&gt;         331         332         333         334         335         336 
#&gt; 0.006856509 0.003481783 0.007782079 0.002644111 0.005562814 0.002695949 
#&gt;         337         338         339         340         341         342 
#&gt; 0.003360827 0.002695949 0.002927342 0.003481783 0.003944568 0.002644111 
#&gt;         343         344         345         346         347         348 
#&gt; 0.003944568 0.002511136 0.003360827 0.003944568 0.002528415 0.002511136 
#&gt;         349         350         351         352         353         354 
#&gt; 0.009117094 0.002695949 0.009445401 0.002695949 0.002511136 0.004868636 
#&gt;         355         356         357         358         359         360 
#&gt; 0.002927342 0.008075828 0.004868636 0.005787445 0.002644111 0.005787445 
#&gt;         361         362         363         364         365         366 
#&gt; 0.003360827 0.002927342 0.004100082 0.005562814 0.002644111 0.004678563 
#&gt;         367         368         369         370         371         372 
#&gt; 0.005562814 0.002695949 0.002511136 0.010965230 0.002927342 0.004100082 
#&gt;         373         374         375         376         377         378 
#&gt; 0.004100082 0.002695949 0.002644111 0.002644111 0.002695949 0.010965230 
#&gt;         379         380         381         382         383         384 
#&gt; 0.003013739 0.002927342 0.004868636 0.002927342 0.002927342 0.003481783 
#&gt;         385         386         387         388         389         390 
#&gt; 0.004678563 0.007782079 0.006856509 0.002511136 0.003013739 0.003013739 
#&gt;         391         392         393         394         395         396 
#&gt; 0.010965230 0.003481783 0.002528415 0.002695949 0.005562814 0.002695949 
#&gt;         397         398         399         400 
#&gt; 0.002644111 0.005562814 0.004868636 0.002528415 
#&gt; 
#&gt; $influence_fit$coefficients
#&gt;       (Intercept)           gre
#&gt; 1   -0.0041872982  6.424343e-06
#&gt; 2   -0.0034576463  8.567095e-06
#&gt; 3   -0.0111018890  2.114636e-05
#&gt; 4   -0.0021127606  6.340949e-06
#&gt; 5   -0.0026729227  3.407979e-06
#&gt; 6   -0.0092305338  1.808324e-05
#&gt; 7    0.0039179492 -3.667698e-06
#&gt; 8   -0.0041667489  6.326534e-06
#&gt; 9    0.0055917359 -6.451379e-06
#&gt; 10   0.0039883102 -8.500745e-06
#&gt; 11   0.0100640955 -1.916962e-05
#&gt; 12  -0.0039292596  5.796908e-06
#&gt; 13  -0.0092305338  1.808324e-05
#&gt; 14   0.0039883102 -8.500745e-06
#&gt; 15  -0.0059558952  1.269449e-05
#&gt; 16  -0.0034311162  4.823789e-06
#&gt; 17   0.0087075923 -1.679441e-05
#&gt; 18  -0.0041420226  6.410240e-06
#&gt; 19   0.0100640955 -1.916962e-05
#&gt; 20   0.0055917359 -6.451379e-06
#&gt; 21  -0.0030845249  4.171233e-06
#&gt; 22  -0.0034576463  8.567095e-06
#&gt; 23  -0.0003740860 -7.565370e-07
#&gt; 24   0.0029812843 -6.722347e-06
#&gt; 25  -0.0092305338  1.808324e-05
#&gt; 26  -0.0111018890  2.114636e-05
#&gt; 27  -0.0007033626  4.005397e-06
#&gt; 28   0.0073335035 -9.350224e-06
#&gt; 29  -0.0101972453  1.966752e-05
#&gt; 30  -0.0026729227  3.407979e-06
#&gt; 31  -0.0021962377  2.533875e-06
#&gt; 32   0.0074226071 -1.454139e-05
#&gt; 33  -0.0003740860 -7.565370e-07
#&gt; 34  -0.0111018890  2.114636e-05
#&gt; 35  -0.0041420226  6.410240e-06
#&gt; 36  -0.0041667489  6.326534e-06
#&gt; 37  -0.0010470382  4.520180e-07
#&gt; 38  -0.0026729227  3.407979e-06
#&gt; 39   0.0091441290 -1.236570e-05
#&gt; 40   0.0073335035 -9.350224e-06
#&gt; 41  -0.0016543393  1.548672e-06
#&gt; 42   0.0023113292 -9.978266e-07
#&gt; 43   0.0007711228  1.559489e-06
#&gt; 44  -0.0030845249  4.171233e-06
#&gt; 45   0.0039883102 -8.500745e-06
#&gt; 46   0.0129757840 -1.875292e-05
#&gt; 47   0.0023113292 -9.978266e-07
#&gt; 48  -0.0030845249  4.171233e-06
#&gt; 49  -0.0039292596  5.796908e-06
#&gt; 50  -0.0041667489  6.326534e-06
#&gt; 51   0.0011700613 -3.511661e-06
#&gt; 52  -0.0039292596  5.796908e-06
#&gt; 53   0.0062082608 -1.240903e-05
#&gt; 54  -0.0047385375  1.068469e-05
#&gt; 55   0.0020420516 -5.059641e-06
#&gt; 56  -0.0082015725  1.639324e-05
#&gt; 57  -0.0016543393  1.548672e-06
#&gt; 58  -0.0041872982  6.424343e-06
#&gt; 59  -0.0041667489  6.326534e-06
#&gt; 60  -0.0003740860 -7.565370e-07
#&gt; 61  -0.0007033626  4.005397e-06
#&gt; 62  -0.0016543393  1.548672e-06
#&gt; 63   0.0011700613 -3.511661e-06
#&gt; 64  -0.0047385375  1.068469e-05
#&gt; 65  -0.0010470382  4.520180e-07
#&gt; 66  -0.0003740860 -7.565370e-07
#&gt; 67   0.0062082608 -1.240903e-05
#&gt; 68   0.0003648247 -2.077545e-06
#&gt; 69  -0.0010470382  4.520180e-07
#&gt; 70   0.0100640955 -1.916962e-05
#&gt; 71   0.0011700613 -3.511661e-06
#&gt; 72  -0.0036074475  5.690286e-06
#&gt; 73  -0.0034311162  4.823789e-06
#&gt; 74  -0.0010470382  4.520180e-07
#&gt; 75   0.0050637430 -1.039591e-05
#&gt; 76   0.0050637430 -1.039591e-05
#&gt; 77  -0.0016543393  1.548672e-06
#&gt; 78  -0.0111018890  2.114636e-05
#&gt; 79  -0.0021962377  2.533875e-06
#&gt; 80  -0.0007033626  4.005397e-06
#&gt; 81   0.0039883102 -8.500745e-06
#&gt; 82   0.0003648247 -2.077545e-06
#&gt; 83  -0.0030845249  4.171233e-06
#&gt; 84  -0.0041872982  6.424343e-06
#&gt; 85   0.0091441290 -1.236570e-05
#&gt; 86  -0.0026729227  3.407979e-06
#&gt; 87  -0.0003740860 -7.565370e-07
#&gt; 88  -0.0003740860 -7.565370e-07
#&gt; 89   0.0039883102 -8.500745e-06
#&gt; 90  -0.0034576463  8.567095e-06
#&gt; 91   0.0039883102 -8.500745e-06
#&gt; 92  -0.0071101240  1.459715e-05
#&gt; 93   0.0100640955 -1.916962e-05
#&gt; 94  -0.0010470382  4.520180e-07
#&gt; 95  -0.0034576463  8.567095e-06
#&gt; 96   0.0020420516 -5.059641e-06
#&gt; 97   0.0011700613 -3.511661e-06
#&gt; 98  -0.0034311162  4.823789e-06
#&gt; 99   0.0039883102 -8.500745e-06
#&gt; 100 -0.0041667489  6.326534e-06
#&gt; 101 -0.0040305739  6.283661e-06
#&gt; 102 -0.0010470382  4.520180e-07
#&gt; 103 -0.0041872982  6.424343e-06
#&gt; 104 -0.0021962377  2.533875e-06
#&gt; 105 -0.0034576463  8.567095e-06
#&gt; 106 -0.0082015725  1.639324e-05
#&gt; 107 -0.0059558952  1.269449e-05
#&gt; 108 -0.0034311162  4.823789e-06
#&gt; 109 -0.0041667489  6.326534e-06
#&gt; 110 -0.0034311162  4.823789e-06
#&gt; 111  0.0029812843 -6.722347e-06
#&gt; 112 -0.0040806610  6.117271e-06
#&gt; 113 -0.0041420226  6.410240e-06
#&gt; 114 -0.0003740860 -7.565370e-07
#&gt; 115  0.0050637430 -1.039591e-05
#&gt; 116  0.0003648247 -2.077545e-06
#&gt; 117  0.0149988949 -2.212814e-05
#&gt; 118  0.0039883102 -8.500745e-06
#&gt; 119 -0.0111018890  2.114636e-05
#&gt; 120 -0.0040305739  6.283661e-06
#&gt; 121  0.0073335035 -9.350224e-06
#&gt; 122  0.0110245535 -1.549937e-05
#&gt; 123 -0.0026729227  3.407979e-06
#&gt; 124 -0.0030845249  4.171233e-06
#&gt; 125  0.0050637430 -1.039591e-05
#&gt; 126 -0.0021962377  2.533875e-06
#&gt; 127  0.0007711228  1.559489e-06
#&gt; 128  0.0062082608 -1.240903e-05
#&gt; 129 -0.0021962377  2.533875e-06
#&gt; 130 -0.0037127097  5.365697e-06
#&gt; 131 -0.0007033626  4.005397e-06
#&gt; 132  0.0011700613 -3.511661e-06
#&gt; 133 -0.0010470382  4.520180e-07
#&gt; 134 -0.0030845249  4.171233e-06
#&gt; 135 -0.0016543393  1.548672e-06
#&gt; 136 -0.0030845249  4.171233e-06
#&gt; 137 -0.0016543393  1.548672e-06
#&gt; 138  0.0039883102 -8.500745e-06
#&gt; 139  0.0003648247 -2.077545e-06
#&gt; 140  0.0007711228  1.559489e-06
#&gt; 141  0.0011700613 -3.511661e-06
#&gt; 142 -0.0059558952  1.269449e-05
#&gt; 143  0.0003648247 -2.077545e-06
#&gt; 144 -0.0010470382  4.520180e-07
#&gt; 145 -0.0010470382  4.520180e-07
#&gt; 146 -0.0041872982  6.424343e-06
#&gt; 147 -0.0034311162  4.823789e-06
#&gt; 148 -0.0016543393  1.548672e-06
#&gt; 149  0.0110245535 -1.549937e-05
#&gt; 150  0.0062082608 -1.240903e-05
#&gt; 151 -0.0111018890  2.114636e-05
#&gt; 152 -0.0041667489  6.326534e-06
#&gt; 153 -0.0021127606  6.340949e-06
#&gt; 154 -0.0010470382  4.520180e-07
#&gt; 155  0.0003648247 -2.077545e-06
#&gt; 156  0.0023113292 -9.978266e-07
#&gt; 157 -0.0016543393  1.548672e-06
#&gt; 158  0.0110245535 -1.549937e-05
#&gt; 159  0.0020420516 -5.059641e-06
#&gt; 160  0.0039883102 -8.500745e-06
#&gt; 161 -0.0003740860 -7.565370e-07
#&gt; 162  0.0011700613 -3.511661e-06
#&gt; 163 -0.0059558952  1.269449e-05
#&gt; 164 -0.0026729227  3.407979e-06
#&gt; 165 -0.0010470382  4.520180e-07
#&gt; 166  0.0039883102 -8.500745e-06
#&gt; 167 -0.0039292596  5.796908e-06
#&gt; 168  0.0050637430 -1.039591e-05
#&gt; 169 -0.0030845249  4.171233e-06
#&gt; 170 -0.0003740860 -7.565370e-07
#&gt; 171 -0.0041667489  6.326534e-06
#&gt; 172 -0.0021962377  2.533875e-06
#&gt; 173  0.0029812843 -6.722347e-06
#&gt; 174 -0.0111018890  2.114636e-05
#&gt; 175 -0.0030845249  4.171233e-06
#&gt; 176 -0.0007033626  4.005397e-06
#&gt; 177 -0.0026729227  3.407979e-06
#&gt; 178 -0.0007033626  4.005397e-06
#&gt; 179  0.0003648247 -2.077545e-06
#&gt; 180 -0.0036074475  5.690286e-06
#&gt; 181  0.0003648247 -2.077545e-06
#&gt; 182 -0.0030845249  4.171233e-06
#&gt; 183  0.0039883102 -8.500745e-06
#&gt; 184  0.0055917359 -6.451379e-06
#&gt; 185 -0.0030845249  4.171233e-06
#&gt; 186  0.0100640955 -1.916962e-05
#&gt; 187 -0.0016543393  1.548672e-06
#&gt; 188 -0.0010470382  4.520180e-07
#&gt; 189 -0.0016543393  1.548672e-06
#&gt; 190 -0.0030845249  4.171233e-06
#&gt; 191 -0.0021127606  6.340949e-06
#&gt; 192  0.0100640955 -1.916962e-05
#&gt; 193  0.0011700613 -3.511661e-06
#&gt; 194 -0.0041872982  6.424343e-06
#&gt; 195  0.0007711228  1.559489e-06
#&gt; 196 -0.0016543393  1.548672e-06
#&gt; 197  0.0020420516 -5.059641e-06
#&gt; 198  0.0192654053 -2.925140e-05
#&gt; 199 -0.0003740860 -7.565370e-07
#&gt; 200 -0.0010470382  4.520180e-07
#&gt; 201  0.0100640955 -1.916962e-05
#&gt; 202  0.0023113292 -9.978266e-07
#&gt; 203 -0.0059558952  1.269449e-05
#&gt; 204 -0.0040806610  6.117271e-06
#&gt; 205  0.0007711228  1.559489e-06
#&gt; 206 -0.0101972453  1.966752e-05
#&gt; 207  0.0062082608 -1.240903e-05
#&gt; 208 -0.0021127606  6.340949e-06
#&gt; 209 -0.0021962377  2.533875e-06
#&gt; 210 -0.0010470382  4.520180e-07
#&gt; 211  0.0062082608 -1.240903e-05
#&gt; 212 -0.0010470382  4.520180e-07
#&gt; 213 -0.0037127097  5.365697e-06
#&gt; 214  0.0011700613 -3.511661e-06
#&gt; 215  0.0007711228  1.559489e-06
#&gt; 216 -0.0034576463  8.567095e-06
#&gt; 217 -0.0040305739  6.283661e-06
#&gt; 218  0.0129757840 -1.875292e-05
#&gt; 219 -0.0037127097  5.365697e-06
#&gt; 220  0.0039179492 -3.667698e-06
#&gt; 221 -0.0021962377  2.533875e-06
#&gt; 222  0.0029812843 -6.722347e-06
#&gt; 223  0.0110245535 -1.549937e-05
#&gt; 224  0.0100640955 -1.916962e-05
#&gt; 225  0.0100640955 -1.916962e-05
#&gt; 226 -0.0071101240  1.459715e-05
#&gt; 227  0.0003648247 -2.077545e-06
#&gt; 228 -0.0021962377  2.533875e-06
#&gt; 229 -0.0034311162  4.823789e-06
#&gt; 230 -0.0071101240  1.459715e-05
#&gt; 231 -0.0010470382  4.520180e-07
#&gt; 232 -0.0003740860 -7.565370e-07
#&gt; 233 -0.0041872982  6.424343e-06
#&gt; 234 -0.0040806610  6.117271e-06
#&gt; 235 -0.0111018890  2.114636e-05
#&gt; 236  0.0003648247 -2.077545e-06
#&gt; 237 -0.0034576463  8.567095e-06
#&gt; 238 -0.0034311162  4.823789e-06
#&gt; 239 -0.0030845249  4.171233e-06
#&gt; 240  0.0039883102 -8.500745e-06
#&gt; 241 -0.0039292596  5.796908e-06
#&gt; 242  0.0073335035 -9.350224e-06
#&gt; 243 -0.0047385375  1.068469e-05
#&gt; 244  0.0003648247 -2.077545e-06
#&gt; 245 -0.0021962377  2.533875e-06
#&gt; 246  0.0100640955 -1.916962e-05
#&gt; 247  0.0029812843 -6.722347e-06
#&gt; 248 -0.0039292596  5.796908e-06
#&gt; 249  0.0029812843 -6.722347e-06
#&gt; 250  0.0011700613 -3.511661e-06
#&gt; 251  0.0020420516 -5.059641e-06
#&gt; 252  0.0003648247 -2.077545e-06
#&gt; 253  0.0073335035 -9.350224e-06
#&gt; 254  0.0055917359 -6.451379e-06
#&gt; 255 -0.0082015725  1.639324e-05
#&gt; 256  0.0011700613 -3.511661e-06
#&gt; 257  0.0073335035 -9.350224e-06
#&gt; 258 -0.0007033626  4.005397e-06
#&gt; 259 -0.0026729227  3.407979e-06
#&gt; 260  0.0011700613 -3.511661e-06
#&gt; 261  0.0029812843 -6.722347e-06
#&gt; 262 -0.0039292596  5.796908e-06
#&gt; 263  0.0073335035 -9.350224e-06
#&gt; 264 -0.0007033626  4.005397e-06
#&gt; 265  0.0073335035 -9.350224e-06
#&gt; 266 -0.0041872982  6.424343e-06
#&gt; 267 -0.0016543393  1.548672e-06
#&gt; 268  0.0007711228  1.559489e-06
#&gt; 269 -0.0047385375  1.068469e-05
#&gt; 270 -0.0030845249  4.171233e-06
#&gt; 271 -0.0021127606  6.340949e-06
#&gt; 272 -0.0021962377  2.533875e-06
#&gt; 273 -0.0047385375  1.068469e-05
#&gt; 274  0.0020420516 -5.059641e-06
#&gt; 275 -0.0026729227  3.407979e-06
#&gt; 276  0.0007711228  1.559489e-06
#&gt; 277 -0.0037127097  5.365697e-06
#&gt; 278  0.0023113292 -9.978266e-07
#&gt; 279 -0.0047385375  1.068469e-05
#&gt; 280 -0.0034576463  8.567095e-06
#&gt; 281  0.0020420516 -5.059641e-06
#&gt; 282 -0.0041420226  6.410240e-06
#&gt; 283  0.0020420516 -5.059641e-06
#&gt; 284 -0.0026729227  3.407979e-06
#&gt; 285  0.0149988949 -2.212814e-05
#&gt; 286 -0.0003740860 -7.565370e-07
#&gt; 287 -0.0111018890  2.114636e-05
#&gt; 288 -0.0034576463  8.567095e-06
#&gt; 289  0.0100640955 -1.916962e-05
#&gt; 290 -0.0040806610  6.117271e-06
#&gt; 291 -0.0007033626  4.005397e-06
#&gt; 292  0.0100640955 -1.916962e-05
#&gt; 293  0.0029812843 -6.722347e-06
#&gt; 294  0.0100640955 -1.916962e-05
#&gt; 295 -0.0034311162  4.823789e-06
#&gt; 296 -0.0026729227  3.407979e-06
#&gt; 297 -0.0016543393  1.548672e-06
#&gt; 298 -0.0037127097  5.365697e-06
#&gt; 299 -0.0021962377  2.533875e-06
#&gt; 300  0.0050637430 -1.039591e-05
#&gt; 301  0.0011700613 -3.511661e-06
#&gt; 302 -0.0034576463  8.567095e-06
#&gt; 303  0.0192654053 -2.925140e-05
#&gt; 304 -0.0047385375  1.068469e-05
#&gt; 305 -0.0019446336  3.116900e-06
#&gt; 306 -0.0010470382  4.520180e-07
#&gt; 307  0.0055917359 -6.451379e-06
#&gt; 308 -0.0010470382  4.520180e-07
#&gt; 309 -0.0021962377  2.533875e-06
#&gt; 310 -0.0039292596  5.796908e-06
#&gt; 311 -0.0016543393  1.548672e-06
#&gt; 312  0.0020420516 -5.059641e-06
#&gt; 313  0.0020420516 -5.059641e-06
#&gt; 314  0.0073335035 -9.350224e-06
#&gt; 315 -0.0021962377  2.533875e-06
#&gt; 316  0.0312787332 -4.933819e-05
#&gt; 317  0.0262352474 -4.090072e-05
#&gt; 318 -0.0101972453  1.966752e-05
#&gt; 319  0.0110245535 -1.549937e-05
#&gt; 320 -0.0021962377  2.533875e-06
#&gt; 321 -0.0037127097  5.365697e-06
#&gt; 322 -0.0037127097  5.365697e-06
#&gt; 323 -0.0030845249  4.171233e-06
#&gt; 324 -0.0040806610  6.117271e-06
#&gt; 325 -0.0026729227  3.407979e-06
#&gt; 326  0.0029812843 -6.722347e-06
#&gt; 327  0.0029812843 -6.722347e-06
#&gt; 328  0.0039179492 -3.667698e-06
#&gt; 329 -0.0010470382  4.520180e-07
#&gt; 330 -0.0030845249  4.171233e-06
#&gt; 331  0.0062082608 -1.240903e-05
#&gt; 332  0.0020420516 -5.059641e-06
#&gt; 333 -0.0040806610  6.117271e-06
#&gt; 334 -0.0016543393  1.548672e-06
#&gt; 335  0.0129757840 -1.875292e-05
#&gt; 336 -0.0007033626  4.005397e-06
#&gt; 337 -0.0026729227  3.407979e-06
#&gt; 338  0.0003648247 -2.077545e-06
#&gt; 339 -0.0021962377  2.533875e-06
#&gt; 340 -0.0034576463  8.567095e-06
#&gt; 341 -0.0030845249  4.171233e-06
#&gt; 342  0.0039179492 -3.667698e-06
#&gt; 343 -0.0030845249  4.171233e-06
#&gt; 344 -0.0010470382  4.520180e-07
#&gt; 345 -0.0026729227  3.407979e-06
#&gt; 346 -0.0030845249  4.171233e-06
#&gt; 347 -0.0003740860 -7.565370e-07
#&gt; 348 -0.0010470382  4.520180e-07
#&gt; 349 -0.0041667489  6.326534e-06
#&gt; 350  0.0003648247 -2.077545e-06
#&gt; 351 -0.0101972453  1.966752e-05
#&gt; 352  0.0003648247 -2.077545e-06
#&gt; 353  0.0023113292 -9.978266e-07
#&gt; 354  0.0039883102 -8.500745e-06
#&gt; 355  0.0055917359 -6.451379e-06
#&gt; 356 -0.0092305338  1.808324e-05
#&gt; 357  0.0039883102 -8.500745e-06
#&gt; 358  0.0050637430 -1.039591e-05
#&gt; 359  0.0039179492 -3.667698e-06
#&gt; 360  0.0050637430 -1.039591e-05
#&gt; 361  0.0073335035 -9.350224e-06
#&gt; 362  0.0055917359 -6.451379e-06
#&gt; 363  0.0029812843 -6.722347e-06
#&gt; 364 -0.0037127097  5.365697e-06
#&gt; 365  0.0039179492 -3.667698e-06
#&gt; 366 -0.0034311162  4.823789e-06
#&gt; 367 -0.0037127097  5.365697e-06
#&gt; 368  0.0003648247 -2.077545e-06
#&gt; 369 -0.0010470382  4.520180e-07
#&gt; 370  0.0100640955 -1.916962e-05
#&gt; 371  0.0055917359 -6.451379e-06
#&gt; 372 -0.0047385375  1.068469e-05
#&gt; 373 -0.0047385375  1.068469e-05
#&gt; 374 -0.0007033626  4.005397e-06
#&gt; 375 -0.0016543393  1.548672e-06
#&gt; 376 -0.0016543393  1.548672e-06
#&gt; 377  0.0003648247 -2.077545e-06
#&gt; 378 -0.0111018890  2.114636e-05
#&gt; 379  0.0011700613 -3.511661e-06
#&gt; 380 -0.0021962377  2.533875e-06
#&gt; 381  0.0039883102 -8.500745e-06
#&gt; 382  0.0055917359 -6.451379e-06
#&gt; 383 -0.0021962377  2.533875e-06
#&gt; 384  0.0020420516 -5.059641e-06
#&gt; 385  0.0110245535 -1.549937e-05
#&gt; 386 -0.0040806610  6.117271e-06
#&gt; 387 -0.0082015725  1.639324e-05
#&gt; 388 -0.0010470382  4.520180e-07
#&gt; 389  0.0011700613 -3.511661e-06
#&gt; 390  0.0011700613 -3.511661e-06
#&gt; 391 -0.0111018890  2.114636e-05
#&gt; 392 -0.0034576463  8.567095e-06
#&gt; 393  0.0007711228  1.559489e-06
#&gt; 394 -0.0007033626  4.005397e-06
#&gt; 395  0.0129757840 -1.875292e-05
#&gt; 396  0.0003648247 -2.077545e-06
#&gt; 397 -0.0016543393  1.548672e-06
#&gt; 398 -0.0037127097  5.365697e-06
#&gt; 399  0.0039883102 -8.500745e-06
#&gt; 400 -0.0003740860 -7.565370e-07
#&gt; 
#&gt; $influence_fit$sigma
#&gt;         1         2         3         4         5         6         7         8 
#&gt; 0.4591698 0.4581543 0.4584799 0.4581026 0.4590470 0.4583932 0.4578820 0.4591559 
#&gt;         9        10        11        12        13        14        15        16 
#&gt; 0.4578233 0.4587999 0.4586160 0.4591244 0.4583932 0.4587999 0.4582537 0.4590881 
#&gt;        17        18        19        20        21        22        23        24 
#&gt; 0.4586556 0.4591825 0.4586160 0.4578233 0.4590682 0.4581543 0.4589499 0.4588325 
#&gt;        25        26        27        28        29        30        31        32 
#&gt; 0.4583932 0.4584799 0.4580496 0.4577630 0.4584371 0.4590470 0.4590246 0.4586938 
#&gt;        33        34        35        36        37        38        39        40 
#&gt; 0.4589499 0.4584799 0.4591825 0.4591559 0.4589761 0.4590470 0.4577013 0.4577630 
#&gt;        41        42        43        44        45        46        47        48 
#&gt; 0.4590009 0.4579393 0.4579951 0.4590682 0.4587999 0.4575731 0.4579393 0.4590682 
#&gt;        49        50        51        52        53        54        55        56 
#&gt; 0.4591244 0.4591559 0.4588938 0.4591244 0.4587305 0.4582047 0.4588638 0.4583480 
#&gt;        57        58        59        60        61        62        63        64 
#&gt; 0.4590009 0.4591698 0.4591559 0.4589499 0.4580496 0.4590009 0.4588938 0.4582047 
#&gt;        65        66        67        68        69        70        71        72 
#&gt; 0.4589761 0.4589499 0.4587305 0.4589225 0.4589761 0.4586160 0.4588938 0.4592135 
#&gt;        73        74        75        76        77        78        79        80 
#&gt; 0.4590881 0.4589761 0.4587659 0.4587659 0.4590009 0.4584799 0.4590246 0.4580496 
#&gt;        81        82        83        84        85        86        87        88 
#&gt; 0.4587999 0.4589225 0.4590682 0.4591698 0.4577013 0.4590470 0.4589499 0.4589499 
#&gt;        89        90        91        92        93        94        95        96 
#&gt; 0.4587999 0.4581543 0.4587999 0.4583015 0.4586160 0.4589761 0.4581543 0.4588638 
#&gt;        97        98        99       100       101       102       103       104 
#&gt; 0.4588938 0.4590881 0.4587999 0.4591559 0.4591940 0.4589761 0.4591698 0.4590246 
#&gt;       105       106       107       108       109       110       111       112 
#&gt; 0.4581543 0.4583480 0.4582537 0.4590881 0.4591559 0.4590881 0.4588325 0.4591407 
#&gt;       113       114       115       116       117       118       119       120 
#&gt; 0.4591825 0.4589499 0.4587659 0.4589225 0.4575066 0.4587999 0.4584799 0.4591940 
#&gt;       121       122       123       124       125       126       127       128 
#&gt; 0.4577630 0.4576380 0.4590470 0.4590682 0.4587659 0.4590246 0.4579951 0.4587305 
#&gt;       129       130       131       132       133       134       135       136 
#&gt; 0.4590246 0.4591069 0.4580496 0.4588938 0.4589761 0.4590682 0.4590009 0.4590682 
#&gt;       137       138       139       140       141       142       143       144 
#&gt; 0.4590009 0.4587999 0.4589225 0.4579951 0.4588938 0.4582537 0.4589225 0.4589761 
#&gt;       145       146       147       148       149       150       151       152 
#&gt; 0.4589761 0.4591698 0.4590881 0.4590009 0.4576380 0.4587305 0.4584799 0.4591559 
#&gt;       153       154       155       156       157       158       159       160 
#&gt; 0.4581026 0.4589761 0.4589225 0.4579393 0.4590009 0.4576380 0.4588638 0.4587999 
#&gt;       161       162       163       164       165       166       167       168 
#&gt; 0.4589499 0.4588938 0.4582537 0.4590470 0.4589761 0.4587999 0.4591244 0.4587659 
#&gt;       169       170       171       172       173       174       175       176 
#&gt; 0.4590682 0.4589499 0.4591559 0.4590246 0.4588325 0.4584799 0.4590682 0.4580496 
#&gt;       177       178       179       180       181       182       183       184 
#&gt; 0.4590470 0.4580496 0.4589225 0.4592135 0.4589225 0.4590682 0.4587999 0.4578233 
#&gt;       185       186       187       188       189       190       191       192 
#&gt; 0.4590682 0.4586160 0.4590009 0.4589761 0.4590009 0.4590682 0.4581026 0.4586160 
#&gt;       193       194       195       196       197       198       199       200 
#&gt; 0.4588938 0.4591698 0.4579951 0.4590009 0.4588638 0.4573687 0.4589499 0.4589761 
#&gt;       201       202       203       204       205       206       207       208 
#&gt; 0.4586160 0.4579393 0.4582537 0.4591407 0.4579951 0.4584371 0.4587305 0.4581026 
#&gt;       209       210       211       212       213       214       215       216 
#&gt; 0.4590246 0.4589761 0.4587305 0.4589761 0.4591069 0.4588938 0.4579951 0.4581543 
#&gt;       217       218       219       220       221       222       223       224 
#&gt; 0.4591940 0.4575731 0.4591069 0.4578820 0.4590246 0.4588325 0.4576380 0.4586160 
#&gt;       225       226       227       228       229       230       231       232 
#&gt; 0.4586160 0.4583015 0.4589225 0.4590246 0.4590881 0.4583015 0.4589761 0.4589499 
#&gt;       233       234       235       236       237       238       239       240 
#&gt; 0.4591698 0.4591407 0.4584799 0.4589225 0.4581543 0.4590881 0.4590682 0.4587999 
#&gt;       241       242       243       244       245       246       247       248 
#&gt; 0.4591244 0.4577630 0.4582047 0.4589225 0.4590246 0.4586160 0.4588325 0.4591244 
#&gt;       249       250       251       252       253       254       255       256 
#&gt; 0.4588325 0.4588938 0.4588638 0.4589225 0.4577630 0.4578233 0.4583480 0.4588938 
#&gt;       257       258       259       260       261       262       263       264 
#&gt; 0.4577630 0.4580496 0.4590470 0.4588938 0.4588325 0.4591244 0.4577630 0.4580496 
#&gt;       265       266       267       268       269       270       271       272 
#&gt; 0.4577630 0.4591698 0.4590009 0.4579951 0.4582047 0.4590682 0.4581026 0.4590246 
#&gt;       273       274       275       276       277       278       279       280 
#&gt; 0.4582047 0.4588638 0.4590470 0.4579951 0.4591069 0.4579393 0.4582047 0.4581543 
#&gt;       281       282       283       284       285       286       287       288 
#&gt; 0.4588638 0.4591825 0.4588638 0.4590470 0.4575066 0.4589499 0.4584799 0.4581543 
#&gt;       289       290       291       292       293       294       295       296 
#&gt; 0.4586160 0.4591407 0.4580496 0.4586160 0.4588325 0.4586160 0.4590881 0.4590470 
#&gt;       297       298       299       300       301       302       303       304 
#&gt; 0.4590009 0.4591069 0.4590246 0.4587659 0.4588938 0.4581543 0.4573687 0.4582047 
#&gt;       305       306       307       308       309       310       311       312 
#&gt; 0.4592379 0.4589761 0.4578233 0.4589761 0.4590246 0.4591244 0.4590009 0.4588638 
#&gt;       313       314       315       316       317       318       319       320 
#&gt; 0.4588638 0.4577630 0.4590246 0.4569928 0.4571487 0.4584371 0.4576380 0.4590246 
#&gt;       321       322       323       324       325       326       327       328 
#&gt; 0.4591069 0.4591069 0.4590682 0.4591407 0.4590470 0.4588325 0.4588325 0.4578820 
#&gt;       329       330       331       332       333       334       335       336 
#&gt; 0.4589761 0.4590682 0.4587305 0.4588638 0.4591407 0.4590009 0.4575731 0.4580496 
#&gt;       337       338       339       340       341       342       343       344 
#&gt; 0.4590470 0.4589225 0.4590246 0.4581543 0.4590682 0.4578820 0.4590682 0.4589761 
#&gt;       345       346       347       348       349       350       351       352 
#&gt; 0.4590470 0.4590682 0.4589499 0.4589761 0.4591559 0.4589225 0.4584371 0.4589225 
#&gt;       353       354       355       356       357       358       359       360 
#&gt; 0.4579393 0.4587999 0.4578233 0.4583932 0.4587999 0.4587659 0.4578820 0.4587659 
#&gt;       361       362       363       364       365       366       367       368 
#&gt; 0.4577630 0.4578233 0.4588325 0.4591069 0.4578820 0.4590881 0.4591069 0.4589225 
#&gt;       369       370       371       372       373       374       375       376 
#&gt; 0.4589761 0.4586160 0.4578233 0.4582047 0.4582047 0.4580496 0.4590009 0.4590009 
#&gt;       377       378       379       380       381       382       383       384 
#&gt; 0.4589225 0.4584799 0.4588938 0.4590246 0.4587999 0.4578233 0.4590246 0.4588638 
#&gt;       385       386       387       388       389       390       391       392 
#&gt; 0.4576380 0.4591407 0.4583480 0.4589761 0.4588938 0.4588938 0.4584799 0.4581543 
#&gt;       393       394       395       396       397       398       399       400 
#&gt; 0.4579951 0.4580496 0.4575731 0.4589225 0.4590009 0.4591069 0.4587999 0.4589499 
#&gt; 
#&gt; $influence_fit$wt.res
#&gt;           1           2           3           4           5           6 
#&gt; -0.16293872  0.62869749  0.52451560  0.64358062 -0.26712061  0.55428185 
#&gt;           7           8           9          10          11          12 
#&gt;  0.70311313 -0.17782184  0.71799626 -0.40106876 -0.47548440 -0.20758810 
#&gt;          13          14          15          16          17          18 
#&gt;  0.55428185 -0.40106876  0.59893124 -0.23735436 -0.46060128 -0.14805559 
#&gt;          19          20          21          22          23          24 
#&gt; -0.47548440  0.71799626 -0.25223748  0.62869749 -0.32665312 -0.38618564 
#&gt;          25          26          27          28          29          30 
#&gt;  0.55428185  0.52451560  0.65846375  0.73287939  0.53939872 -0.26712061 
#&gt;          31          32          33          34          35          36 
#&gt; -0.28200374 -0.44571815 -0.32665312  0.52451560 -0.14805559 -0.17782184 
#&gt;          37          38          39          40          41          42 
#&gt; -0.31177000 -0.26712061  0.74776252  0.73287939 -0.29688687  0.68823000 
#&gt;          43          44          45          46          47          48 
#&gt;  0.67334688 -0.25223748 -0.40106876  0.77752877  0.68823000 -0.25223748 
#&gt;          49          50          51          52          53          54 
#&gt; -0.20758810 -0.17782184 -0.35641938 -0.20758810 -0.43083502  0.61381436 
#&gt;          55          56          57          58          59          60 
#&gt; -0.37130251  0.56916498 -0.29688687 -0.16293872 -0.17782184 -0.32665312 
#&gt;          61          62          63          64          65          66 
#&gt;  0.65846375 -0.29688687 -0.35641938  0.61381436 -0.31177000 -0.32665312 
#&gt;          67          68          69          70          71          72 
#&gt; -0.43083502 -0.34153625 -0.31177000 -0.47548440 -0.35641938 -0.10340620 
#&gt;          73          74          75          76          77          78 
#&gt; -0.23735436 -0.31177000 -0.41595189 -0.41595189 -0.29688687  0.52451560 
#&gt;          79          80          81          82          83          84 
#&gt; -0.28200374  0.65846375 -0.40106876 -0.34153625 -0.25223748 -0.16293872 
#&gt;          85          86          87          88          89          90 
#&gt;  0.74776252 -0.26712061 -0.32665312 -0.32665312 -0.40106876  0.62869749 
#&gt;          91          92          93          94          95          96 
#&gt; -0.40106876  0.58404811 -0.47548440 -0.31177000  0.62869749 -0.37130251 
#&gt;          97          98          99         100         101         102 
#&gt; -0.35641938 -0.23735436 -0.40106876 -0.17782184 -0.13317246 -0.31177000 
#&gt;         103         104         105         106         107         108 
#&gt; -0.16293872 -0.28200374  0.62869749  0.56916498  0.59893124 -0.23735436 
#&gt;         109         110         111         112         113         114 
#&gt; -0.17782184 -0.23735436 -0.38618564 -0.19270497 -0.14805559 -0.32665312 
#&gt;         115         116         117         118         119         120 
#&gt; -0.41595189 -0.34153625  0.79241190 -0.40106876  0.52451560 -0.13317246 
#&gt;         121         122         123         124         125         126 
#&gt;  0.73287939  0.76264564 -0.26712061 -0.25223748 -0.41595189 -0.28200374 
#&gt;         127         128         129         130         131         132 
#&gt;  0.67334688 -0.43083502 -0.28200374 -0.22247123  0.65846375 -0.35641938 
#&gt;         133         134         135         136         137         138 
#&gt; -0.31177000 -0.25223748 -0.29688687 -0.25223748 -0.29688687 -0.40106876 
#&gt;         139         140         141         142         143         144 
#&gt; -0.34153625  0.67334688 -0.35641938  0.59893124 -0.34153625 -0.31177000 
#&gt;         145         146         147         148         149         150 
#&gt; -0.31177000 -0.16293872 -0.23735436 -0.29688687  0.76264564 -0.43083502 
#&gt;         151         152         153         154         155         156 
#&gt;  0.52451560 -0.17782184  0.64358062 -0.31177000 -0.34153625  0.68823000 
#&gt;         157         158         159         160         161         162 
#&gt; -0.29688687  0.76264564 -0.37130251 -0.40106876 -0.32665312 -0.35641938 
#&gt;         163         164         165         166         167         168 
#&gt;  0.59893124 -0.26712061 -0.31177000 -0.40106876 -0.20758810 -0.41595189 
#&gt;         169         170         171         172         173         174 
#&gt; -0.25223748 -0.32665312 -0.17782184 -0.28200374 -0.38618564  0.52451560 
#&gt;         175         176         177         178         179         180 
#&gt; -0.25223748  0.65846375 -0.26712061  0.65846375 -0.34153625 -0.10340620 
#&gt;         181         182         183         184         185         186 
#&gt; -0.34153625 -0.25223748 -0.40106876  0.71799626 -0.25223748 -0.47548440 
#&gt;         187         188         189         190         191         192 
#&gt; -0.29688687 -0.31177000 -0.29688687 -0.25223748  0.64358062 -0.47548440 
#&gt;         193         194         195         196         197         198 
#&gt; -0.35641938 -0.16293872  0.67334688 -0.29688687 -0.37130251  0.82217816 
#&gt;         199         200         201         202         203         204 
#&gt; -0.32665312 -0.31177000 -0.47548440  0.68823000  0.59893124 -0.19270497 
#&gt;         205         206         207         208         209         210 
#&gt;  0.67334688  0.53939872 -0.43083502  0.64358062 -0.28200374 -0.31177000 
#&gt;         211         212         213         214         215         216 
#&gt; -0.43083502 -0.31177000 -0.22247123 -0.35641938  0.67334688  0.62869749 
#&gt;         217         218         219         220         221         222 
#&gt; -0.13317246  0.77752877 -0.22247123  0.70311313 -0.28200374 -0.38618564 
#&gt;         223         224         225         226         227         228 
#&gt;  0.76264564 -0.47548440 -0.47548440  0.58404811 -0.34153625 -0.28200374 
#&gt;         229         230         231         232         233         234 
#&gt; -0.23735436  0.58404811 -0.31177000 -0.32665312 -0.16293872 -0.19270497 
#&gt;         235         236         237         238         239         240 
#&gt;  0.52451560 -0.34153625  0.62869749 -0.23735436 -0.25223748 -0.40106876 
#&gt;         241         242         243         244         245         246 
#&gt; -0.20758810  0.73287939  0.61381436 -0.34153625 -0.28200374 -0.47548440 
#&gt;         247         248         249         250         251         252 
#&gt; -0.38618564 -0.20758810 -0.38618564 -0.35641938 -0.37130251 -0.34153625 
#&gt;         253         254         255         256         257         258 
#&gt;  0.73287939  0.71799626  0.56916498 -0.35641938  0.73287939  0.65846375 
#&gt;         259         260         261         262         263         264 
#&gt; -0.26712061 -0.35641938 -0.38618564 -0.20758810  0.73287939  0.65846375 
#&gt;         265         266         267         268         269         270 
#&gt;  0.73287939 -0.16293872 -0.29688687  0.67334688  0.61381436 -0.25223748 
#&gt;         271         272         273         274         275         276 
#&gt;  0.64358062 -0.28200374  0.61381436 -0.37130251 -0.26712061  0.67334688 
#&gt;         277         278         279         280         281         282 
#&gt; -0.22247123  0.68823000  0.61381436  0.62869749 -0.37130251 -0.14805559 
#&gt;         283         284         285         286         287         288 
#&gt; -0.37130251 -0.26712061  0.79241190 -0.32665312  0.52451560  0.62869749 
#&gt;         289         290         291         292         293         294 
#&gt; -0.47548440 -0.19270497  0.65846375 -0.47548440 -0.38618564 -0.47548440 
#&gt;         295         296         297         298         299         300 
#&gt; -0.23735436 -0.26712061 -0.29688687 -0.22247123 -0.28200374 -0.41595189 
#&gt;         301         302         303         304         305         306 
#&gt; -0.35641938  0.62869749  0.82217816  0.61381436 -0.04387369 -0.31177000 
#&gt;         307         308         309         310         311         312 
#&gt;  0.71799626 -0.31177000 -0.28200374 -0.20758810 -0.29688687 -0.37130251 
#&gt;         313         314         315         316         317         318 
#&gt; -0.37130251  0.73287939 -0.28200374  0.89659380  0.86682754  0.53939872 
#&gt;         319         320         321         322         323         324 
#&gt;  0.76264564 -0.28200374 -0.22247123 -0.22247123 -0.25223748 -0.19270497 
#&gt;         325         326         327         328         329         330 
#&gt; -0.26712061 -0.38618564 -0.38618564  0.70311313 -0.31177000 -0.25223748 
#&gt;         331         332         333         334         335         336 
#&gt; -0.43083502 -0.37130251 -0.19270497 -0.29688687  0.77752877  0.65846375 
#&gt;         337         338         339         340         341         342 
#&gt; -0.26712061 -0.34153625 -0.28200374  0.62869749 -0.25223748  0.70311313 
#&gt;         343         344         345         346         347         348 
#&gt; -0.25223748 -0.31177000 -0.26712061 -0.25223748 -0.32665312 -0.31177000 
#&gt;         349         350         351         352         353         354 
#&gt; -0.17782184 -0.34153625  0.53939872 -0.34153625  0.68823000 -0.40106876 
#&gt;         355         356         357         358         359         360 
#&gt;  0.71799626  0.55428185 -0.40106876 -0.41595189  0.70311313 -0.41595189 
#&gt;         361         362         363         364         365         366 
#&gt;  0.73287939  0.71799626 -0.38618564 -0.22247123  0.70311313 -0.23735436 
#&gt;         367         368         369         370         371         372 
#&gt; -0.22247123 -0.34153625 -0.31177000 -0.47548440  0.71799626  0.61381436 
#&gt;         373         374         375         376         377         378 
#&gt;  0.61381436  0.65846375 -0.29688687 -0.29688687 -0.34153625  0.52451560 
#&gt;         379         380         381         382         383         384 
#&gt; -0.35641938 -0.28200374 -0.40106876  0.71799626 -0.28200374 -0.37130251 
#&gt;         385         386         387         388         389         390 
#&gt;  0.76264564 -0.19270497  0.56916498 -0.31177000 -0.35641938 -0.35641938 
#&gt;         391         392         393         394         395         396 
#&gt;  0.52451560  0.62869749  0.67334688  0.65846375  0.77752877 -0.34153625 
#&gt;         397         398         399         400 
#&gt; -0.29688687 -0.22247123 -0.40106876 -0.32665312 
#&gt; 
#&gt; 
#&gt; $model_fit_assumptions_test
#&gt;                           Value      p-value                   Decision
#&gt; Global Stat        65.312437028 2.211564e-13 Assumptions NOT satisfied!
#&gt; Skewness           36.445627012 1.569849e-09 Assumptions NOT satisfied!
#&gt; Kurtosis           28.227937555 1.078368e-07 Assumptions NOT satisfied!
#&gt; Link Function       0.002173853 9.628124e-01    Assumptions acceptable.
#&gt; Heteroscedasticity  0.636698608 4.249088e-01    Assumptions acceptable.
#&gt; 
#&gt; $fit_diagnostics
#&gt;       Adj_R2      AIC      BIC
#&gt; 1 0.03158891 515.5995 527.5739
#&gt; 
#&gt; $plot_diagnostics
#&gt; NULL
#&gt; </div><div class='input'><span class='co'># }</span>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Sheeja Manchira Krishnan.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


